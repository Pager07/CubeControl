#Goals:
1. Contorl a virtul cube with my hand
2. I should be able to do the following transformation:
	- Rotate the cube 
	- Enlarge the cube
	- Translate the cube 
3. I should be able to detect hand keypoints 
  - obtain keypoints of 1 hand with respective to whole image  
  - obtain keypoints of 2 hand with respective to whole image 

#Goal 1 Steps:
 1. Render the cube 
 	1a. learn to render basic cube
 	1b. learn to add transforamtion to the cube
 		- [ ] trasnlation 
 		- [x]  rotation
 		- [x] enlargement
 2. Obtain finger points model
 3. Map the finger points to the cube transformation 

 #Questions
  - What is a VertexShader?
  	- It's a programmable shader
  	- Handles the processing of individual vertices 
  	- Vertex shaders are fed Vertex Attribute data, as specified from a vertex array object by a drawing command. 
  	- A vertex shader receives a single vertex from the vertex stream and generates a single vertex to the output vertex stream


  - What is a Fragment Shader?
  	-  Fargments are surrface points generated by the Resterizer
  	- A Fragment Shader is the Shader stage that will process a Fragment generated by the Rasterization into a set of colors and a single depth value.
  	- The output of a fragment shader is a depth value, a possible stencil value (unmodified by the fragment shader), and zero or more color values to be potentially written to the buffers in the current framebuffers.



  - What are the different Buffers that are needed?  	
    - vertexBuffer
    	- used as a source for vertex array data. 
    - indexBuffer
    	- An index buffer is essentially an array of pointers into the vertex buffer. 
    	- It allows you to reorder the vertex data, and reuse existing data for multiple vertices. 
    	- https://vulkan-tutorial.com/Vertex_buffers/Index_buffer#:~:text=An%20index%20buffer%20is%20essen
tially,existing%20data%20for%20multiple%20vertices.

  	- arrayBuffer
  	- axesVertexBuffer

  - What are the different types of variable?
  	- Attributes
  		- Passed from app to vertex shader
  		- in other words: input variables used in the vertex shader
  		- points to a vertex buffer object

  	- Uniforms 
  		- Passed from app to shaders(vertex and fargment)
  	- Varings
  		- are used for passing data from the vertex shader and the fargment shader 
  		- Interpolating data between VERTEX and FRAGMENT shaders.
  		- Write in vertex 
  		- so in essence they are passing information down the pipeline.
  	- https://sites.google.com/site/pavelkolodin/js-javascript/webgl

 
  - What are the different matrix needed?
  	- A great guide is at:
  		- http://www.opengl-tutorial.org/beginners-tutorials/tutorial-3-matrices/#the-model-view-and-projection-matrices
  	- modelMatrix
  		- allow us to map model coordinates to world coordinates 
  	- viewMatrix
  		- This allow you to map world coordinates to camera coordinates
  		- "if you want to view a moutain from another angle, you can either move the cameraâ€¦ or move the mountain"

  	- projmatrix
  		- maps the camera coordinates space to frustum/cube sapve 
  		- everything inside the cube is on screen
  		- this defines the part of the scene that the camera is able to see
  		- The matrix basically deforms the objects in a way that the closer objects are bigger and far objects are smaller

  	- g_normalMatrix

    - mvp_Matrix   
  - How to apply transformation to the cube?
    - modelMatrix.setTranslate()
    - modelMatrix.rotate(angel, x,y,z)

  - What do we have to in the main function?
    -
# Transforming the cube using keyboard:
  - Rotation
     - Arrow keys
  - Translation 
    - 
  - Scale
    - a,s,d,f




#Goal 2 Steps:
  1. Find a model for hand pose detection
    1a. Load the model [x]
    1b. Get Test prediction [x]
  2. Build a pipeline for inference
    2a.  Use Webcam.js to feed video input [x] 
    2b. Get prediction on video feed [x]
    2c. Visualize prediction
      - Draw tensor image to canvas [x]
      - Draw the keypoints to the canvas [x]
    2d. Run experiment to improve the prediction
      - Check if there is any addition transformation we are applying to the image in webcam.js [x]
      - Check if cropping the webcam.js affects the prediction
      - Check if increasing the size of the video element [x]
    2e. Visualization on webgl
        - Use ScatterPlot libary to plot to draw a 3d interactable plot [x]


#Question:
- What model will I be using?
  - https://tfhub.dev/mediapipe/tfjs-model/handskeleton/1/default/1
- How to use tfhub model in js?
  - The author of the model has uploaded the model as npm package, I will just npm install via npm
- How can I test my model has been loaded?
  - How to run the html file?
    - Use Chorme Web server to host the main folder or else it may not work
    - Common error was 'tainted canvas' due to CROS
- How to visualize the data?
  - Inimate the form the  following 
    - https://storage.googleapis.com/tfjs-models/demos/handpose/index.html
  - Because we need to draw the pose
    - We will have to draw the image into ctx
        - 
- Does the webcam.js resize the image?
  - Experimentation is needed to check if crop affects the models, prediction

- What Library to plot 3D graph
  - ScatterGL
- How to use the ScatterGl library?
  - Look into ScatterGl Api to get a sense
  - is stats object realated to ScatterGl? 
    - No, its for the fps display, which is also very coo
  - What is the dat object used for?
    - 

#Goals 3 steps:
  1. Translate the cube using 1 hand
    - 1a. Translate the cube given (x,y,z) [x] 
    - 1b. Generate (x,y,z) from hands
      - Make a button to stop-start prediciton [x]
      - Find the mean (x,y,z) for hand pose[x]

    - 1c. Translate the cube using hands (x,y,z)
  2. Rotate the cube using 1 hand 
  3. Enlarge the cube with 2 hands 

- What are the ways to detect 2 hands?
  1. Use hand tracker to find hands then cop the image area and pass it to model
    - https://towardsdatascience.com/handtrackjs-677c29c1d585
  2. Split the image assuming your 2 hands going to be in 2 different side of image
    - Better latency


  - How to translate the cube using hand pose?
    - Train a 3D conv with LSTM (i think this is overdoing it)
    - Generate the direction of movement vector of hand and translate the cube in that particular direction

  - How to translate the cube in a given direction?
    - How are we moving the top part of the hand?
      - we are using translate/rotaate function
      - What matrix are we applying tat to?
        - Applying it to modelMatrix
      - Why not projection or view matrix?
        - What transformation are we applying to the projection matirx?
          - nothing: we just apply setPerspetive and lookAt()
        - What does lookAt() function do?
          - lookAt(M, eye_x, eye_y, eye_z, center_x, center_y, center_z, up_dx, up_dy, up_dz)
  - What does my output look like from the pose model?
    - 